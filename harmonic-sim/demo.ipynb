{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Harmonic similarity demo\n",
    "\n",
    "**Notes for improvements**\n",
    "- For computational reasons, it is better to start comparing n-grams from the lowest order (e.g. 2, 3) and stop as soon as there are no more elements in common. For instance, if there are no repeated patterns of len 4 between two sequences under comparison, it does not make sense to try  with anything > 4. This can speed up computation of the hsim.\n",
    "- Instead of saving the actual full ngrams for each track, we should consider creating a table of all the possible ngrams that were found across all the dataset. This  way track A will say \"I have ngrams x, y, ...\" which can then be read from such a different table. This would reduce the space complexity.\n",
    "- In addition, to speed up comparison, we should create another table -- using the indices of the previous table (the index for all the ngrams), to save all those tracks that each specific ngram. The mapping is <from the index of the ngram> to the list of all the track (ids) that have that recurring pattern. This should easily allow comparing 1 given track to all the others in one shot, rather than performing trivial 1-to-1 comparisons.\n",
    "- The current code works on ngrams computed from tracks that were **not** transposed to the same key (considering the current encodings), so the harmonic similarity should be much higher, in principle, once we manage to address this point.\n",
    "- The second term h_corr of our full measure of harmonic similarity (see Notion) is the most computationally demanding part, because it requires re-computing the recurring patterns from the concatenated sequences. Not supported for the moment, but we can consider as FW, as we will be able to retrieve more matches and increase the whole similarity score.\n",
    "- **Doing graph analysis of the resulting graph (see the Extra section) seems a very very promising direction!**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import joblib\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from harmonic_lib import ngram_hsim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading and re-shaping the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "with open(\"./sonar_ngrams.joblib\", \"rb\") as fo:\n",
    "    ngrams_bag = joblib.load(fo)\n",
    "\n",
    "with open(\"./sonar_encoding_bundle.joblib\", \"rb\") as fo:\n",
    "    data_bundle = joblib.load(fo)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "encdec = data_bundle[\"encoder_decoder\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "ngrams_bag[\"isophonics_0\"][:10]  # just an example to visualise"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(209, 93, 19),\n",
       " (120, 173, 120),\n",
       " (263, 46, 19),\n",
       " (46, 19, 42),\n",
       " (19, 42, 42),\n",
       " (138, 46, 46),\n",
       " (42, 138, 46),\n",
       " (42, 19, 19),\n",
       " (19, 120, 120),\n",
       " (42, 120, 19)]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing the similarity: an example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "a_rpbag = ngrams_bag[\"isophonics_0\"]\n",
    "b_rpbag = ngrams_bag[\"isophonics_155\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "hsim_score, longest_rp = ngram_hsim(a_rpbag, b_rpbag)\n",
    "\n",
    "print(\"h_sim = {0:.4f} based on longest recurrent pattern(s): {1}\"\n",
    "      .format(hsim_score, longest_rp))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "h_sim = 0.0000 based on longest recurrent pattern(s): []\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing the similarity: all tracks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "track_ids = list(ngrams_bag.keys())\n",
    "hsim_map = {track_id: {} for track_id in track_ids}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for i, track_a in enumerate(track_ids):\n",
    "    a_rpbag = ngrams_bag[track_a]  # fix for now\n",
    "    for j in range(i+1, len(track_ids)):  # move ahead\n",
    "        track_b = track_ids[j]\n",
    "        b_rpbag = ngrams_bag[track_b]\n",
    "\n",
    "        hsim, longest_rps = ngram_hsim(a_rpbag, b_rpbag)\n",
    "        if hsim > 0.:  # save only non-trivial\n",
    "            hsim_map[track_a][track_b] = hsim, longest_rps\n",
    "            hsim_map[track_b][track_a] = hsim, longest_rps\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#hsim_map[\"isophonics_0\"][\"isophonics_155\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(\"./sonar_hsim_map.joblib\", \"wb\") as fo:\n",
    "    joblib.dump({\"hsim_map\": hsim_map}, fo)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extra"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bokeh.io import output_notebook, show, save\n",
    "from bokeh.models import Circle, MultiLine, HoverTool, NodesAndLinkedEdges\n",
    "from bokeh.plotting import figure, from_networkx\n",
    "from bokeh.palettes import Greys256, Blues256, Spectral8\n",
    "from bokeh.transform import linear_cmap\n",
    "\n",
    "output_notebook()\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.bokehjs_load.v0+json": "",
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "for track_id in track_ids:\n",
    "    if len(hsim_map[track_id]) > 0:\n",
    "        G.add_node(track_id)\n",
    "\n",
    "for track_a in hsim_map:\n",
    "    for track_b in hsim_map[track_a]:\n",
    "        if not G.has_edge(track_b, track_a):\n",
    "            hsim_val, lsrp = hsim_map[track_a][track_b]\n",
    "            # Decode the longest shared recurrent pattern\n",
    "            #lsrp = [encdec.decode_event(idx) for idx in lsrp]\n",
    "            G.add_edge(track_a, track_b, weight=hsim_val, lsrp=lsrp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Some basic network analysis\n",
    "degrees_dict = dict(nx.degree(G))\n",
    "nx.set_node_attributes(G, name='degree', values=degrees_dict)\n",
    "\n",
    "degrees = list(degrees_dict.values())\n",
    "communities = nx.algorithms.community.greedy_modularity_communities(G)\n",
    "\n",
    "mod_class, mod_color = {}, {}\n",
    "# Loop through each community in the network\n",
    "for community_number, community in enumerate(communities):\n",
    "    # For each member of the community, add their community number and a distinct color\n",
    "    for name in community: \n",
    "        mod_class[name] = community_number\n",
    "        mod_color[name] = Spectral8[community_number]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def rescale(val, min_val, max_val, new_range=(1, 20)):\n",
    "    normalised = ((val - min_val)*(new_range[1] - new_range[0])) / (max_val - min_val)\n",
    "    return new_range[0] + normalised\n",
    "\n",
    "min_degree, max_degree = min(degrees), max(degrees)\n",
    "node_size = dict([(node, rescale(degree, min_degree, max_degree)) \\\n",
    "    for node, degree in nx.degree(G)])\n",
    "\n",
    "nx.set_node_attributes(G, name='node_size', values=node_size)\n",
    "# Add modularity class and color as attributes from the network above\n",
    "nx.set_node_attributes(G, mod_class, 'modularity_cls')\n",
    "nx.set_node_attributes(G, mod_color, 'modularity_col')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "dataset_cols = {\n",
    "    \"isophonics\": \"black\",\n",
    "    \"jaah\": \"red\",\n",
    "    \"schubert-winterreise\": \"yellow\"}\n",
    "\n",
    "dataset_nodes = {node: dataset_cols[node.split(\"_\")[0]] for node in list(G.nodes)}\n",
    "nx.set_node_attributes(G, dataset_nodes, 'dataset_col')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "title = 'Harmonic similarity network'\n",
    "\n",
    "# Colouring options\n",
    "edge_palette = Greys256[::-1]\n",
    "node_palette = Blues256[::-1]\n",
    "# From palettes to colourmaps\n",
    "edge_cmap = linear_cmap(\n",
    "    'weight', edge_palette, 0, 1)\n",
    "node_degree_cmap = linear_cmap(\n",
    "    \"degree\", node_palette, min(degrees), max(degrees))\n",
    "\n",
    "#Create a plot — set dimensions, toolbar, and title\n",
    "plot = figure(tools=\"pan,wheel_zoom,save,reset,tap\",\n",
    "              active_scroll='wheel_zoom', title=title)\n",
    "# Create a network graph object with spring layout\n",
    "network_graph = from_networkx(G, nx.spring_layout, scale=10, center=(0, 0))\n",
    "\n",
    "# Set the colour and size of nodes and edges\n",
    "network_graph.node_renderer.glyph = Circle(\n",
    "    size=\"node_size\", fill_color=\"modularity_col\", line_color=\"dataset_col\")\n",
    "network_graph.edge_renderer.glyph = MultiLine(\n",
    "    line_color=edge_cmap,\n",
    "    line_alpha=0.5, line_width=1)\n",
    "\n",
    "# Selection behaviour: change of col/size\n",
    "network_graph.node_renderer.selection_glyph = Circle(\n",
    "    size=10, fill_color=\"white\", line_width=.5)\n",
    "network_graph.edge_renderer.selection_glyph = MultiLine(\n",
    "    line_color=\"black\", line_width=2)\n",
    "\n",
    "network_graph.selection_policy = NodesAndLinkedEdges()\n",
    "network_graph.inspection_policy = NodesAndLinkedEdges()\n",
    "\n",
    "# Hovering behaviour: show information\n",
    "hover_edges = HoverTool(\n",
    "    tooltips=[\n",
    "        (\"hsim\", \"@weight\"),\n",
    "        (\"lsrp\", \"@lsrp\")],\n",
    "    renderers=[network_graph.edge_renderer],\n",
    "    line_policy=\"interp\")\n",
    "\n",
    "hover_nodes = HoverTool(\n",
    "    tooltips=[\n",
    "        (\"track\",\"@index\"), \n",
    "        (\"degree\", \"@degree\"), \n",
    "        (\"Modularity Class\", \"@modularity_cls\")],\n",
    "    renderers=[network_graph.node_renderer])\n",
    "\n",
    "#A dd network graph to the plot\n",
    "plot.renderers.append(network_graph)\n",
    "plot.add_tools(hover_edges, hover_nodes)\n",
    "\n",
    "#show(plot)\n",
    "save(plot, filename=f\"test.html\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Users/jacopodeberardinis/Documents/projects/sonar2021_demo/harmonic-sim/test.html'"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('musilar': conda)"
  },
  "interpreter": {
   "hash": "a063213f03792ab588fc7e41dfc745810b8fe87fd60955dc8fcac58d288503d5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}